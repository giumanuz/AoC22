{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giumanuz/AoC22/blob/main/Tesi_SATELLITI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kakbf3M_aU4r",
        "outputId": "e8522705-56e4-433f-9ff3-b3bda376c52f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTS OK\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as tr\n",
        "from skimage import io\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "\n",
        "# Models\n",
        "# from unet import Unet\n",
        "# from siamunet_conc import SiamUnet_conc\n",
        "# from siamunet_diff import SiamUnet_diff\n",
        "# from fresunet import FresUNet\n",
        "\n",
        "# Other\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "# from skimage import io\n",
        "from scipy.ndimage import zoom\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "from tqdm import tqdm as tqdm\n",
        "from pandas import read_csv\n",
        "from math import floor, ceil, sqrt, exp\n",
        "from IPython import display\n",
        "import time\n",
        "from itertools import chain\n",
        "import time\n",
        "import warnings\n",
        "from pprint import pprint\n",
        "\n",
        "import random\n",
        "\n",
        "# Function for setting the seed\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    # torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "print('IMPORTS OK')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ_iwWJgEC9Z",
        "outputId": "d40cc597-56e1-467d-f91d-44e4c13df1fc"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zzin-Ra8aU4u",
        "outputId": "4b40bf28-aa98-4b4a-ec5c-90f1a331f2c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEFINITIONS OK\n"
          ]
        }
      ],
      "source": [
        "# Global Variables' Definitions\n",
        "\n",
        "PATH_TO_DATASET = '/content/drive/MyDrive/Start'\n",
        "PATH_TO_LABELS = '/content/drive/MyDrive/Finish'\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "PATCH_SIDE = 96\n",
        "N_EPOCHS = 50\n",
        "\n",
        "NORMALISE_IMGS = True\n",
        "\n",
        "LOAD_TRAINED = False\n",
        "\n",
        "DATA_AUG = True\n",
        "\n",
        "\n",
        "print('DEFINITIONS OK')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ78FsnqaU4v",
        "outputId": "24130a17-fe06-4eab-9d5b-3cbee32576a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['top_potsdam_2_10_IRRG.tif', 'top_potsdam_2_11_IRRG.tif', 'top_potsdam_2_12_IRRG.tif', 'top_potsdam_2_13_IRRG.tif', 'top_potsdam_2_14_IRRG.tif', 'top_potsdam_3_10_IRRG.tif', 'top_potsdam_3_11_IRRG.tif', 'top_potsdam_3_12_IRRG.tif', 'top_potsdam_3_13_IRRG.tif', 'top_potsdam_3_14_IRRG.tif', 'top_potsdam_4_10_IRRG.tif', 'top_potsdam_4_11_IRRG.tif', 'top_potsdam_4_12_IRRG.tif', 'top_potsdam_4_13_IRRG.tif', 'top_potsdam_4_14_IRRG.tif', 'top_potsdam_4_15_IRRG.tif', 'top_potsdam_5_10_IRRG.tif', 'top_potsdam_5_11_IRRG.tif', 'top_potsdam_5_12_IRRG.tif', 'top_potsdam_5_13_IRRG.tif', 'top_potsdam_5_14_IRRG.tif', 'top_potsdam_5_15_IRRG.tif', 'top_potsdam_6_7_IRRG.tif', 'top_potsdam_6_8_IRRG.tif', 'top_potsdam_6_9_IRRG.tif', 'top_potsdam_6_10_IRRG.tif', 'top_potsdam_6_11_IRRG.tif', 'top_potsdam_6_12_IRRG.tif', 'top_potsdam_6_13_IRRG.tif', 'top_potsdam_6_14_IRRG.tif', 'top_potsdam_6_15_IRRG.tif', 'top_potsdam_7_7_IRRG.tif', 'top_potsdam_7_8_IRRG.tif', 'top_potsdam_7_9_IRRG.tif', 'top_potsdam_7_10_IRRG.tif', 'top_potsdam_7_11_IRRG.tif', 'top_potsdam_7_12_IRRG.tif', 'top_potsdam_7_13_IRRG.tif']\n"
          ]
        }
      ],
      "source": [
        "def get_tif_images(tif_path):\n",
        "    images = []\n",
        "    for filename in os.listdir(tif_path):\n",
        "        if filename.endswith('.tif'):\n",
        "            images.append(filename)\n",
        "    return images\n",
        "\n",
        "print(get_tif_images(PATH_TO_DATASET))\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom class to load the dataset\n",
        "    \"\"\"\n",
        "    def __init__(self, tif_path, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tif_path (string): path to tif files\n",
        "            transform (callable, optional): Optional transform to be applied on a sample\n",
        "        \"\"\"\n",
        "        # read tif files from tif_path directory\n",
        "        self.transform = transform\n",
        "        self.names = get_tif_images(tif_path)\n",
        "\n",
        "\n",
        "        self.data = torch.zeros(len(self.names), 3, PATCH_SIDE, PATCH_SIDE)\n",
        "        self.labels = torch.zeros(len(self.names), 1, PATCH_SIDE, PATCH_SIDE, dtype=torch.long)\n",
        "\n",
        "        for idx, name in enumerate(self.names):\n",
        "            img_name = os.path.join(tif_path, name)\n",
        "            image = io.imread(img_name)\n",
        "            label_name = os.path.join(PATH_TO_LABELS, name[:-9] + '_label.tif')\n",
        "            label = io.imread(label_name)\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "                label = self.transform(label)\n",
        "\n",
        "            label = self.convert_image(label)\n",
        "            self.data[idx] = image\n",
        "            self.labels[idx] = label\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def closest_to_one(self, num):\n",
        "        if abs(num - 1) < abs(num - 0):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "\n",
        "    def convert_image(self, tensor):\n",
        "        \"\"\"\n",
        "        Convert tensor from 3 channel to one channel, and associate it a number from 0 to 5\n",
        "        \"\"\"\n",
        "        # Crea una mappa dei colori\n",
        "        color_map = {}\n",
        "\n",
        "        # transform image in tensor\n",
        "        # tensor = torch.tensor(image)\n",
        "\n",
        "        # print(tensor.shape)\n",
        "        \n",
        "        for x in range(tensor.size(1)):\n",
        "            for y in range(tensor.size(2)):\n",
        "                pixel_value = tensor[:, x, y]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                # pixel_value=pixel_value.tolist()\n",
        "                # for idx, elem in enumerate(pixel_value):\n",
        "                #     pixel_value[idx] = self.closest_to_one(elem)\n",
        "                # pixel_value = torch.tensor(pixel_value)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                if not torch.equal(pixel_value, torch.tensor([0, 0, 0])):\n",
        "                    if tuple(pixel_value.tolist()) not in color_map:\n",
        "                        color_map[tuple(pixel_value.tolist())] = len(color_map)\n",
        "        \n",
        "        converted_tensor = torch.zeros(1, tensor.size(1), tensor.size(2), dtype=torch.long)\n",
        "    \n",
        "        for x in range(tensor.size(1)):\n",
        "            for y in range(tensor.size(2)):\n",
        "                pixel_value = tensor[:, x, y]\n",
        "\n",
        "                \n",
        "                color = color_map.get(tuple(pixel_value.tolist()), 0)\n",
        "                \n",
        "                # Imposta il valore del pixel nel nuovo tensore\n",
        "                converted_tensor[0, x, y] = color      #modify\n",
        "        \n",
        "        # Stampa il tensore convertito\n",
        "        # print(\"Tensore convertito:\")\n",
        "        # print(converted_tensor)\n",
        "\n",
        "\n",
        "        counts = torch.bincount(converted_tensor.flatten(), minlength=6)\n",
        "        for key, value in color_map.items():\n",
        "            print(f\"{value}: {key} --- n_volte: {counts[value]}\")\n",
        "\n",
        "\n",
        "\n",
        "        return converted_tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "JajszWlUaU4y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "422974ed-1dac-4a58-9629-67acc86b556b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: (0, 1, 0) --- n_volte: 2068\n",
            "1: (0, 1, 1) --- n_volte: 3349\n",
            "2: (1, 1, 1) --- n_volte: 1416\n",
            "3: (0, 0, 1) --- n_volte: 1090\n",
            "4: (1, 0, 0) --- n_volte: 1244\n",
            "5: (1, 1, 0) --- n_volte: 49\n",
            "0: (1, 1, 1) --- n_volte: 2909\n",
            "1: (1, 0, 0) --- n_volte: 697\n",
            "2: (0, 1, 1) --- n_volte: 2977\n",
            "3: (0, 1, 0) --- n_volte: 1820\n",
            "4: (1, 1, 0) --- n_volte: 78\n",
            "5: (0, 0, 1) --- n_volte: 735\n",
            "0: (0, 0, 1) --- n_volte: 2198\n",
            "1: (0, 1, 1) --- n_volte: 3997\n",
            "2: (1, 1, 1) --- n_volte: 1404\n",
            "3: (0, 1, 0) --- n_volte: 1508\n",
            "4: (1, 1, 0) --- n_volte: 71\n",
            "5: (1, 0, 0) --- n_volte: 38\n",
            "0: (1, 1, 1) --- n_volte: 2374\n",
            "1: (0, 1, 0) --- n_volte: 2133\n",
            "2: (0, 1, 1) --- n_volte: 2724\n",
            "3: (1, 0, 0) --- n_volte: 167\n",
            "4: (0, 0, 1) --- n_volte: 1710\n",
            "5: (1, 1, 0) --- n_volte: 108\n",
            "0: (0, 1, 1) --- n_volte: 4948\n",
            "1: (1, 1, 1) --- n_volte: 1191\n",
            "2: (0, 1, 0) --- n_volte: 2622\n",
            "3: (1, 0, 0) --- n_volte: 22\n",
            "4: (0, 0, 1) --- n_volte: 375\n",
            "5: (1, 1, 0) --- n_volte: 58\n",
            "0: (0, 0, 1) --- n_volte: 2309\n",
            "1: (1, 1, 1) --- n_volte: 1920\n",
            "2: (0, 1, 0) --- n_volte: 1871\n",
            "3: (0, 1, 1) --- n_volte: 2554\n",
            "4: (1, 0, 0) --- n_volte: 466\n",
            "5: (1, 1, 0) --- n_volte: 96\n",
            "0: (0, 1, 1) --- n_volte: 3960\n",
            "1: (0, 1, 0) --- n_volte: 1322\n",
            "2: (1, 1, 0) --- n_volte: 89\n",
            "3: (0, 0, 1) --- n_volte: 1424\n",
            "4: (1, 1, 1) --- n_volte: 2078\n",
            "5: (1, 0, 0) --- n_volte: 343\n",
            "0: (1, 1, 0) --- n_volte: 1625\n",
            "1: (1, 1, 1) --- n_volte: 2305\n",
            "2: (0, 0, 1) --- n_volte: 2064\n",
            "3: (0, 1, 0) --- n_volte: 1509\n",
            "4: (0, 1, 1) --- n_volte: 1500\n",
            "5: (1, 0, 0) --- n_volte: 213\n",
            "0: (0, 0, 1) --- n_volte: 3200\n",
            "1: (0, 1, 1) --- n_volte: 1854\n",
            "2: (1, 1, 1) --- n_volte: 2043\n",
            "3: (1, 0, 0) --- n_volte: 191\n",
            "4: (0, 1, 0) --- n_volte: 1796\n",
            "5: (1, 1, 0) --- n_volte: 132\n",
            "0: (0, 1, 1) --- n_volte: 2877\n",
            "1: (0, 1, 0) --- n_volte: 2230\n",
            "2: (1, 1, 1) --- n_volte: 1854\n",
            "3: (1, 0, 0) --- n_volte: 200\n",
            "4: (1, 1, 0) --- n_volte: 116\n",
            "5: (0, 0, 1) --- n_volte: 1939\n",
            "0: (0, 0, 1) --- n_volte: 2770\n",
            "1: (0, 1, 1) --- n_volte: 2528\n",
            "2: (0, 1, 0) --- n_volte: 1688\n",
            "3: (1, 1, 1) --- n_volte: 1645\n",
            "4: (1, 0, 0) --- n_volte: 478\n",
            "5: (1, 1, 0) --- n_volte: 107\n",
            "0: (0, 1, 1) --- n_volte: 2662\n",
            "1: (0, 1, 0) --- n_volte: 1564\n",
            "2: (1, 1, 1) --- n_volte: 2109\n",
            "3: (0, 0, 1) --- n_volte: 2598\n",
            "4: (1, 1, 0) --- n_volte: 108\n",
            "5: (1, 0, 0) --- n_volte: 175\n",
            "0: (0, 0, 1) --- n_volte: 9216\n",
            "1: (1, 0, 0) --- n_volte: 0\n",
            "2: (1, 1, 1) --- n_volte: 0\n",
            "3: (0, 1, 1) --- n_volte: 0\n",
            "4: (0, 1, 0) --- n_volte: 0\n",
            "5: (1, 1, 0) --- n_volte: 0\n",
            "0: (1, 1, 1) --- n_volte: 3271\n",
            "1: (0, 0, 1) --- n_volte: 2830\n",
            "2: (0, 1, 0) --- n_volte: 1114\n",
            "3: (0, 1, 1) --- n_volte: 1237\n",
            "4: (1, 0, 0) --- n_volte: 578\n",
            "5: (1, 1, 0) --- n_volte: 186\n",
            "0: (1, 1, 1) --- n_volte: 3518\n",
            "1: (1, 1, 0) --- n_volte: 162\n",
            "2: (0, 1, 1) --- n_volte: 1769\n",
            "3: (0, 1, 0) --- n_volte: 1515\n",
            "4: (1, 0, 0) --- n_volte: 881\n",
            "5: (0, 0, 1) --- n_volte: 1371\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-b8570eb0c142>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtif_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH_TO_DATASET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-115-7219fb1a00c6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tif_path, transform)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtif_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mlabel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_LABELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_label.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                                (plugin, kind))\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/io/_plugins/tifffile_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img_num'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtifffile_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(files, aszarr, key, series, level, squeeze, maxworkers, mode, name, offset, size, pattern, axesorder, categories, imread, sort, container, chunkshape, dtype, axestiled, ioworkers, chunkmode, fillvalue, zattrs, multiscales, omexml, out, out_inplace, _multifile, _useframes, **kwargs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m                         \u001b[0mmultiscales\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiscales\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m                     )\n\u001b[0;32m-> 1086\u001b[0;31m                 return tif.asarray(\n\u001b[0m\u001b[1;32m   1087\u001b[0m                     \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m                     \u001b[0mseries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(self, key, series, level, squeeze, out, maxworkers)\u001b[0m\n\u001b[1;32m   4263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpage0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4264\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'page is None'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4265\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4267\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(self, out, squeeze, lock, maxworkers)\u001b[0m\n\u001b[1;32m   8921\u001b[0m                 \u001b[0;31m#     pass  # corrupted file, e.g., with too many strips\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8923\u001b[0;31m             for _ in self.segments(\n\u001b[0m\u001b[1;32m   8924\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8925\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36msegments\u001b[0;34m(self, lock, maxworkers, func, sort, _fullsize)\u001b[0m\n\u001b[1;32m   8722\u001b[0m                 \u001b[0mflat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8723\u001b[0m             ):\n\u001b[0;32m-> 8724\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8726\u001b[0m             \u001b[0;31m# reduce memory overhead by processing chunks of up to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(args, decodeargs, decode)\u001b[0m\n\u001b[1;32m   8710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8711\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecodeargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecodeargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeyframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8712\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecodeargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxworkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmaxworkers\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36mdecode_other\u001b[0;34m(data, index, jpegtables, jpegheader, _fullsize)\u001b[0m\n\u001b[1;32m   8639\u001b[0m                 \u001b[0;31m# TODO: calculate correct size for packed integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8640\u001b[0m                 \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8641\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8642\u001b[0m             \u001b[0mdata_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8643\u001b[0m             \u001b[0;31m# del data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tifffile/_imagecodecs.py\u001b[0m in \u001b[0;36mpackbits_decode\u001b[0;34m(encoded, out)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m129\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;31m# replicate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0mout_extend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m258\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                 \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m129\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if DATA_AUG:\n",
        "    data_transform = tr.Compose([\n",
        "        tr.ToPILImage(),\n",
        "        tr.RandomHorizontalFlip(), \n",
        "        tr.RandomVerticalFlip(), \n",
        "        tr.RandomRotation(180),\n",
        "        tr.Resize((PATCH_SIDE, PATCH_SIDE), interpolation=InterpolationMode.NEAREST),\n",
        "        tr.ToTensor(),\n",
        "    ])\n",
        "else:\n",
        "    data_transform = None\n",
        "\n",
        "\n",
        "dataset = MyDataset(tif_path=PATH_TO_DATASET, transform=data_transform)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.names[12])"
      ],
      "metadata": {
        "id": "98Oqtu37yXsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if NORMALISE_IMGS:\n",
        "    mean = torch.mean(dataset.data, dim=(0, 2, 3), keepdim=True)\n",
        "    std = torch.std(dataset.data, dim=(0, 2, 3), keepdim=True) \n",
        "\n",
        "    print(f'mean: {mean}')\n",
        "    print(f'std: {std}')\n",
        "\n",
        "    print(dataset.data.shape)\n",
        "\n",
        "    dataset.data = (dataset.data - mean) / std"
      ],
      "metadata": {
        "id": "FA-NwhQItHuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "print('DATASET OK')"
      ],
      "metadata": {
        "id": "WZS8F24glTxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSyk82jIaU4z"
      },
      "outputs": [],
      "source": [
        "print(next(iter(train_dataloader))[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-4Zq9z3aU40"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "\n",
        "class DoubleConvolution(nn.Module):\n",
        "\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(DoubleConvolution, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, input_channels=3, output_channels=1,\n",
        "                 features=[64, 128, 256, 512]):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Encoder \n",
        "        for f in features:\n",
        "            self.downs.append(DoubleConvolution(input_channels, f))\n",
        "            input_channels = f\n",
        "\n",
        "        # lower bottleneck layers\n",
        "        self.bottleneck = DoubleConvolution(features[-1], features[-1] * 2)\n",
        "\n",
        "        # Decoder\n",
        "        for f in reversed(features):\n",
        "            self.ups.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Upsample(scale_factor=2),\n",
        "                    nn.Conv2d(in_channels=2 * f, out_channels=f, kernel_size=3,\n",
        "                              padding=1),\n",
        "                ))\n",
        "            self.ups.append(DoubleConvolution(2 * f, f))\n",
        "\n",
        "        self.final_convolution = nn.Conv2d(in_channels=features[0],\n",
        "                                           out_channels=output_channels,\n",
        "                                           kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = list()\n",
        "        for module in self.downs:\n",
        "            x = module(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        skip_connections = skip_connections[::-1]  # reverse order\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        for i in range(0, len(self.ups), 2):\n",
        "            x = self.ups[i](x)\n",
        "            skip_connection = skip_connections[i // 2]\n",
        "            if skip_connection.shape != x.shape:\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:],\n",
        "                              interpolation=TF.InterpolationMode.NEAREST)\n",
        "            x = torch.cat([skip_connection, x], dim=1)\n",
        "            x = self.ups[i + 1](x)\n",
        "\n",
        "        x = self.final_convolution(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ2olI70aU41"
      },
      "outputs": [],
      "source": [
        "# train\n",
        "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device='cuda'):\n",
        "    for epoch in range(epochs):\n",
        "        training_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            output = model(inputs).to(device)\n",
        "            loss = loss_fn(output, targets.squeeze(1))  # modify\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.data.item() * inputs.size(0)\n",
        "            print(\"ciao\")\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        model.eval()\n",
        "        num_correct = 0 \n",
        "        num_examples = 0\n",
        "        for batch in val_loader:\n",
        "            inputs, targets = batch\n",
        "            inputs = inputs.to(device)\n",
        "            output = model(inputs)\n",
        "            targets = targets.to(device)\n",
        "            loss = loss_fn(output, targets.squeeze(1))  # modify\n",
        "            valid_loss += loss.data.item() * inputs.size(0)\n",
        "        valid_loss /= len(val_loader.dataset)\n",
        "        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, training_loss, valid_loss))\n",
        "\n",
        "# test\n",
        "def test(model, test_loader, device='cuda'):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    num_correct = 0 \n",
        "    num_examples = 0\n",
        "    for batch in test_loader:\n",
        "        inputs, targets = batch\n",
        "        inputs = inputs.to(device)\n",
        "        output = model(inputs)\n",
        "        targets = targets.to(device)\n",
        "        loss = loss_fn(output, targets)\n",
        "        test_loss += loss.data.item() * inputs.size(0)\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('Test Loss: {:.4f}'.format(test_loss))\n",
        "\n",
        "# create model\n",
        "\n",
        "\n",
        "\n",
        "model = UNet(input_channels=3, output_channels=6)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "class_counts = torch.bincount(dataset.labels.flatten())\n",
        "print(class_counts)\n",
        "     \n",
        "class_weights = 1.0 / class_counts.float()\n",
        "class_weights /= torch.sum(class_weights)\n",
        "class_weights = class_weights.to(device)  # Move class_weights to CUDA device\n",
        "\n",
        "print(class_weights)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "# train\n",
        "train(model, optimizer, loss_fn, train_dataloader, test_dataloader, epochs=N_EPOCHS, device=device)\n",
        "\n",
        "# test\n",
        "test(model, test_dataloader, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "test(model, test_dataloader, device=device)"
      ],
      "metadata": {
        "id": "BLmDppqtQlhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Valori dell'epoch e training loss\n",
        "epochs = list(range(50))\n",
        "training_loss = [1.6720, 1.6712, 1.6714, 1.5992, 1.6178, 1.6141, 1.6306, 1.6682, 1.6405, 1.6349, 1.6153, 1.6410, 1.6804, 1.5805, 1.6081, 1.6171, 1.6613, 1.6400, 1.6406, 1.6639, 1.6242, 1.6031, 1.6117, 1.6504, 1.6335, 1.5848, 1.6550, 1.5941, 1.6115, 1.6011, 1.5929, 1.6480, 1.6041, 1.6028, 1.5579, 1.6334, 1.6339, 1.6265, 1.6217, 1.6433, 1.5718, 1.6148, 1.6083, 1.6162, 1.6040, 1.6548, 1.6762, 1.6452, 1.6120, 1.5993]\n",
        "\n",
        "# Valore del test loss\n",
        "test_loss = 1.6232\n",
        "\n",
        "# Plot del training loss\n",
        "plt.plot(epochs, training_loss, label='Training Loss')\n",
        "\n",
        "# Linea per il test loss\n",
        "plt.axhline(y=test_loss, color='r', linestyle='--', label='Test Loss')\n",
        "\n",
        "# Etichette degli assi\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Titolo del grafico\n",
        "plt.title('Training Loss and Test Loss')\n",
        "\n",
        "# Legenda\n",
        "plt.legend()\n",
        "\n",
        "# Mostra il grafico\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wuXsMwiBR69G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}